{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Pareto sets in high dimensions: How can regularization help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from multiple_regression import *\n",
    "from fairness import *\n",
    "from plotting import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the effect of unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_matrix = run_multiple_regression_experiment_unlabeled_sparsity(\n",
    "        random_seed = 42,                                                           # fix random seed\n",
    "        num_experiments = 10,                                                       # number of experiments to run\n",
    "        d = 50,                                                                     # dimension\n",
    "        s_array = np.arange(5,50,5),                                                # sparsity of ground truths\n",
    "        n = 15,                                                                     # number of labeled samples\n",
    "        N_array = np.arange(15, 55, 5),                                             # number of unlabeled samples\n",
    "        noise_var = 0.5,                                                            # variance of the noise\n",
    "        cov_stabilizer= 0.5,                                                        # stabilizes the condition number of the random covariance matrix A^TA + stab + I -  the smaller, the more adversarial for directly regularized methods\n",
    "        lambda_fixed = 0.5,                                                         # fixed preference vectors lambda (only first component)\n",
    "        ts_ensemble_reg_params = np.array(2*[1 for s in np.arange(5,50,5)]),        # regularization strengths for two-stage ensemble\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sparsity_unlabeled_matrix(errors_matrix, np.arange(15, 55, 5), np.arange(5,50,5), save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pareto fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regs = [1,5,7,8,8]\n",
    "errors_PF, av_cond_number = run_multiple_regression_experiment_PF(\n",
    "    random_seed = 42,                                                   # fix random seed\n",
    "    num_experiments = 10,                                               # number of experiments\n",
    "    d = 100,                                                            # dimension \n",
    "    s = 1,                                                              # sparsity level\n",
    "    n = 20,                                                             # number of labeled datapoints\n",
    "    N = 200,                                                            # number of unlabeled datapoints\n",
    "    noise_var = 0.5,                                                    # variance of the additive noise\n",
    "    cov_stabilizer = 0.2,                                               # the covariances are ranomly selected. The sabilizer ensures a minimum eigenvalue of the covariance matrix.\n",
    "    lambdas = np.linspace(0,1,10),                                      # preference weights of the ensemble\n",
    "    dr_ensemble_reg_params = np.array(regs+list(reversed(regs))),       # regularization parameters of the directly regularized ensemble\n",
    "    dr_hypernetwork_regfun = lambda x: 1+0.5*x*(1-x),                   # regularization parameters of the directly regularized hypernetwork\n",
    "    ts_ensemble_reg_params = np.array([1,1]),                           # regularization parameters of the two-stage ensemble\n",
    "    ts_hypernetwork_regfun = lambda x: 0,                               # regularization parameters of the two-stage hypernetwork\n",
    "    num_epochs = 3000,                                                  # number of training epochs for the hypernetworks\n",
    "    verbose = False,                                                    # verbosity of training the ensembles\n",
    "    hn_verbose = False                                                  # verbostiy of training the hypernetworks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Pareto_fronts(\n",
    "    errors_PF, \n",
    "    title=' ', \n",
    "    save = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = {\n",
    "    \"name\":\"communities\",                           # name of the dataset. one of 'communities', 'adult', 'hsls', 'enem'\n",
    "    \"protected_index\": 7,                           # index of protected attribute\n",
    "    \"train_size\": 1000,                             # training set size -> split into labeled and unlabeled\n",
    "    \"test_size\": 1000,                              # test set size\n",
    "    \"labeled_size\": 150,                            # number of labeled training samples. must be <= training_size\n",
    "    \"num_noisy_feats\": 0,                           # number of artificial noisy features to add\n",
    "    \"dr_ensemble_reg_params\": 10*[0.04],            # regularization parameters for directly regularized ensemble\n",
    "    \"ts_ensemble_reg_params\": [0.04,0.04],          # regularization parameters for two-stage ensemble\n",
    "    \"eval_metric\": \"square_loss\"                    # one of 'error_rate' and 'square_loss'\n",
    "}\n",
    "adult = {\n",
    "    \"name\":\"adult\",\n",
    "    \"protected_index\": 9,\n",
    "    \"train_size\": 10_000,\n",
    "    \"test_size\": 30_000,\n",
    "    \"labeled_size\": 500,\n",
    "    \"num_noisy_feats\": 100,\n",
    "    \"dr_ensemble_reg_params\": 10*[0.01],\n",
    "    \"ts_ensemble_reg_params\": [0.01,0.01],\n",
    "    \"eval_metric\": \"error_rate\"\n",
    "}\n",
    "hsls = {\n",
    "    \"name\":\"hsls\",\n",
    "    \"protected_index\": 57,\n",
    "    \"train_size\": 5000,\n",
    "    \"test_size\": 5000,\n",
    "    \"labeled_size\": 1000,\n",
    "    \"num_noisy_feats\": 0,\n",
    "    \"dr_ensemble_reg_params\": 10*[0.01],\n",
    "    \"ts_ensemble_reg_params\": [0.01,0.01],\n",
    "    \"eval_metric\": \"error_rate\"\n",
    "}\n",
    "enem = {\n",
    "    \"name\":\"enem\",\n",
    "    \"protected_index\": 1,\n",
    "    \"train_size\": 10_000,\n",
    "    \"test_size\": 5_000,\n",
    "    \"labeled_size\": 2000,\n",
    "    \"num_noisy_feats\": 0,\n",
    "    \"dr_ensemble_reg_params\": 10*[0.01],\n",
    "    \"ts_ensemble_reg_params\": [0.01,0.01],\n",
    "    \"eval_metric\": \"error_rate\"\n",
    "}\n",
    "dataset_list = [communities,adult,hsls,enem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = run_experiments_fairness_PF(\n",
    "        random_seed = 42,                                   # fix the random seed\n",
    "        num_experiments = 20,                               # number of experiments\n",
    "        dataset_list = dataset_list,    # datasets included in the experiment (parameters specified above)\n",
    "        lambdas = np.linspace(0,1,10),                      # preference weights of the ensembles\n",
    "        verbose = False                                   # verbosity\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fairness_Pareto_fronts(\n",
    "    errordict = errors, \n",
    "    title = 'fairness',\n",
    "    xlabels = ['square loss on test data','error rate on test data','error rate on test data','error rate on test data','error rate on test data'], \n",
    "    save = False, \n",
    "    xmax = [0.4,0.23,0.34,0.45],\n",
    "    xmin = [0,0.2,0.25,0.28],\n",
    "    ymax = [0.2,0.013,0.0025,0.01]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
